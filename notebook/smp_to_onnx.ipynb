{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook to convert SMP models to onnx and verify model results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import segmentation_models_pytorch as smp\n",
    "from catalyst.utils import unpack_checkpoint, load_checkpoint\n",
    "import torch \n",
    "import cv2\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"../outputs/2022-01-17/03-50-40/\"\n",
    "\n",
    "cfg = OmegaConf.load(os.path.join(log_dir, \".hydra/config.yaml\"))\n",
    "\n",
    "\n",
    "#load model\n",
    "model = eval(\n",
    "    f\"smp.{cfg.model.ARCH}(encoder_name='{cfg.model.ENCODER}',encoder_weights='{cfg.model.ENCODER_WEIGHTS}',classes={len(cfg.model.CLASSES)},activation=('{cfg.model.ACTIVATION}'))\"\n",
    ")\n",
    "\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(cfg.model.ENCODER, cfg.model.ENCODER_WEIGHTS)\n",
    "preprocessing_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load checkpoint\n",
    "checkpoint = load_checkpoint(\n",
    "    path=os.path.join(log_dir, cfg.training.LOG_DIR, \"best_full.pth\")\n",
    ")\n",
    "\n",
    "#remove unwanted value pairs\n",
    "unpack_checkpoint(\n",
    "    checkpoint=checkpoint,\n",
    "    model=model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output_dir = \"../deployment/models/\"\n",
    "os.makedirs(model_output_dir,exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(1, 3, 320, 320, device='cpu')\n",
    "torch.onnx.export(model, dummy_input, os.path.join(model_output_dir,\"model.onnx\"), input_names=[\"input\"], output_names=[\"output\"], verbose=False,opset_version=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test onnx model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as rt\n",
    "import numpy as np\n",
    "\n",
    "model = rt.InferenceSession(os.path.join(model_output_dir,\"model.onnx\"))\n",
    "input_name = model.get_inputs()[0].name\n",
    "label_name = model.get_outputs()[0].name\n",
    "print(label_name,input_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"../data/training_data/train/midaxial1775.png\")\n",
    "\n",
    "# 255107942.0_TXZJEF00000806NeighOrtho00000794N_190208.jpg\n",
    "#./data/benchmark_data/images/258173907.0_TXZSAN00000906NeighOrtho00002531N_190128.jpg\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image)\n",
    "org_img = image.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image,image_size = (320,320)):\n",
    "    mean=[0.485, 0.456, 0.406]\n",
    "    std=[0.229, 0.224, 0.225]\n",
    "\n",
    "    image = cv2.resize(image,image_size)\n",
    "    # image_viz =image.copy()\n",
    "    image = image.astype('float32')/255\n",
    "    image -=mean\n",
    "    image /=std\n",
    "    image = image.transpose(2, 0, 1)\n",
    "\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    # image.shape\n",
    "    return image\n",
    "\n",
    "image= preprocess(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infer from onnx model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mask = model.run(None, {'input': image})[0]\n",
    "pred_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post process mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synap",
   "language": "python",
   "name": "synap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
